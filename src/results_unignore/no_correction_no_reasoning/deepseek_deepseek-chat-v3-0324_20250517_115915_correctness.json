{
  "timestamp": "2025-05-17T11:59:15.921993",
  "metadata": {
    "model_name": "deepseek/deepseek-chat-v3-0324",
    "dataset_length": 210,
    "batch_size": 256
  },
  "total_per_track": {
    "implicit_no_reasoning_no_correction": 1469,
    "explicit_no_reasoning_no_correction": 1469
  },
  "tally_sum": {
    "implicit_no_reasoning_no_correction": 1307,
    "explicit_no_reasoning_no_correction": 932
  },
  "length_by_difficulty": {
    "implicit_no_reasoning_no_correction": {
      "easy": 166,
      "medium": 148,
      "hard": 116
    },
    "explicit_no_reasoning_no_correction": {
      "easy": 118,
      "medium": 55,
      "hard": 16
    }
  },
  "degradation_buckets": {
    "implicit_no_reasoning_no_correction": {
      "0": {
        "total": 232,
        "correct": 194
      },
      "1": {
        "total": 310,
        "correct": 278
      },
      "2": {
        "total": 276,
        "correct": 252
      },
      "3": {
        "total": 259,
        "correct": 231
      },
      "4": {
        "total": 214,
        "correct": 195
      },
      "5": {
        "total": 113,
        "correct": 101
      },
      "6": {
        "total": 44,
        "correct": 41
      },
      "7": {
        "total": 13,
        "correct": 11
      },
      "8": {
        "total": 5,
        "correct": 3
      },
      "9": {
        "total": 1,
        "correct": 0
      },
      "10": {
        "total": 1,
        "correct": 1
      },
      "11": {
        "total": 1,
        "correct": 0
      }
    },
    "explicit_no_reasoning_no_correction": {
      "0": {
        "total": 365,
        "correct": 261
      },
      "1": {
        "total": 533,
        "correct": 329
      },
      "2": {
        "total": 444,
        "correct": 262
      },
      "3": {
        "total": 108,
        "correct": 68
      },
      "4": {
        "total": 12,
        "correct": 8
      },
      "5": {
        "total": 5,
        "correct": 3
      },
      "6": {
        "total": 2,
        "correct": 1
      }
    }
  },
  "permutation_stats": {
    "implicit_no_reasoning_no_correction": {
      "added_rules": {
        "total": 1222,
        "correct": 1097
      },
      "added_facts": {
        "total": 714,
        "correct": 649
      },
      "removed_rules": {
        "total": 790,
        "correct": 715
      },
      "removed_facts": {
        "total": 309,
        "correct": 264
      },
      "no_change": {
        "total": 13,
        "correct": 8
      }
    },
    "explicit_no_reasoning_no_correction": {
      "removed_facts": {
        "total": 309,
        "correct": 224
      },
      "removed_rules": {
        "total": 790,
        "correct": 514
      },
      "added_rules": {
        "total": 1222,
        "correct": 783
      },
      "added_facts": {
        "total": 714,
        "correct": 471
      },
      "no_change": {
        "total": 13,
        "correct": 1
      }
    }
  },
  "confidence_intervals_95": {
    "implicit_no_reasoning_no_correction": {
      "p": 0.8897208985704561,
      "rand_lower": 0.8732521831989288,
      "rand_upper": 0.905152291059494,
      "det_lower": 0.8725769146062324,
      "det_upper": 0.9052879678671857
    },
    "explicit_no_reasoning_no_correction": {
      "p": 0.6344452008168823,
      "rand_lower": 0.6096504628658295,
      "rand_upper": 0.6587421000003815,
      "det_lower": 0.609228546103239,
      "det_upper": 0.659122959018396
    }
  }
}